## 模型/框架支持情况

当前，MindIE SD支持魔乐社区, vLLM Omni, Cache Dit等框架/社区，不同社区的具体使能方法请参考example，

理论上，MindIE SD支持任何多模态模型的推理加速，此处仅列出了我们测试过的典型模型的特性叠加和性能最新情况。
我们将会持续刷新相关数据，如果你将MindIE SD适配到了新模型，欢迎更新example，刷新列表。

### 模型支持情况
|  模型       |  vLLM Omni | Cache DiT + diffusers |  魔乐社区  |
|:----------:|:---------:|:---------------------:|:------:|
| Flux.1-dev |     ✅️    |          ✅️           |  ✅️    |

### vLLM Omni的特性&模型性能

|   模型     |  硬件  | Cache   | 并行 | 稀疏FA | 量化 | 融合算子 |       性能       | 说明 |
|:----------:|:----:|:-------:|:--:|:----:|:--:|:---------:|:--------------:|:--:| 
| Flux.1-dev |  A2  |    ✅️    | ✅️  |  ✅️   | ✅️ |   ✅️    | xxx (yy steps) |    |

说明：
A2代表xxx，默认使用的版本算力xxxT，内存xx GB。
### Cache DiT + diffusers的特性&模型性能


### 魔乐社区的特性叠加&模型性能
